{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Vấn đề bài toán \n",
    "\n",
    "Cho đến nay, chúng ta đã cùng nhau xét một số bài toán về Linear Regression, Logistic Regression,... Nhưng một số vấn đề có thể gặp cho các bài toán này là Underfitting và Overfitting\n",
    "\n",
    "#### 1.1 Overfitting  và Underfitting \n",
    "\n",
    "- Overfitting (còn được gọi là high variance): \n",
    "    - Là hiện tượng mô hình dự đoán quá khớp với tập training set, dẫn đến dự đoán không hiệu quả đối với tập testing set.\n",
    "    - Giá trị hàm Loss đối với Traning Set giảm nhưng với bộ Test tăng.\n",
    "    \n",
    "- Underfitting (còn được gọi là high bias): \n",
    "    - Là hiện tượng mô hình quá đơn giản không thể khái quát hoá được bộ dữ liệu training, dẫn đến dự đoán trên training và tập test đều sai nhiều. \n",
    "    - Giá trị hàm Loss đối với Traning Set và bộ Test đều cao, chưa đạt được đến giá trị tối ưu.\n",
    "    \n",
    "- Good-fit: mô hình dự đoán khái quát được cả với tập training và tập test. \n",
    "\n",
    "<img src=\"images/Bias-Variance.png\" style=\"width:50%;height:50%;\">\n",
    "\n",
    "\n",
    "#### 1.2 Overfitting  và Underfitting  cho bài toán Linear Regression \n",
    "\n",
    "Ví dụ về bài toán dự đoán giá nhà dựa trên kích thước.\n",
    "\n",
    "<img src=\"images/overfitting_1.png\" style=\"width:70%;height:70%;\">\n",
    "\n",
    "- Overfitting (vấn đề quá khớp) - High variance: Mô hình là hàm đa thức bậc 2 quá phức tạp dẫn đến khớp với mọi điểm dữ liệu trong Training Set.\n",
    "\n",
    "- Underfitting - High bias: Mô hình quá đơn giản là một đường thẳng tuyến tính, không thể dự đoán chính xác. \n",
    "\n",
    "\n",
    "#### 1.3 Overfitting  và Underfitting  cho bài toán Logistic Regression \n",
    "\n",
    "Tương tự như bài toán Linear Regression, vấn đề trong bài toán Logistic là Decision Boundary quá khớp hoặc không khái quát được bài toán.\n",
    "\n",
    "<img src=\"images/overfitting_2.png\" style=\"width:70%;height:70%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Khắc phục vấn đề \n",
    "\n",
    "Một số kỹ thuật thường được dùng:\n",
    "\n",
    "- Cross - Validation: Cross validation là một cải tiến của validation với lượng dữ liệu trong tập validation là nhỏ nhưng chất lượng mô hình được đánh giá trên nhiều tập validation khác nhau.\n",
    "\n",
    "- Early Stopping: dừng trước khi mô hình trở lên quá mức (over-fitting).\n",
    "\n",
    "- Regularization: một cách cơ bản, là thay đổi mô hình một chút để tránh overfitting trong khi vẫn giữ được tính tổng quát của nó (tính tổng quát là tính mô tả được nhiều dữ liệu, trong cả tập training và test).\n",
    "\n",
    "Trong bài này, chúng ta sẽ sử dụng kỹ thuật Regularization để tránh hiện tượng Over-fitting. Các phương pháp khác sẽ được học ở bài tiếp theo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Regularization\n",
    "\n",
    "Kỹ thuật regularization phổ biến nhất là thêm vào hàm mất mát một số hạng nữa. Số hạng này thường dùng để đánh giá độ phức tạp của mô hình. Hàm mất mát mới này thường được gọi là **regularized loss function**.\n",
    "\n",
    "#### 2.1 Cost Function\n",
    "\n",
    "Giả sử hàm giả thuyết: $h_\\theta(x) = \\theta_0 + \\theta_1x + \\theta_2x^2 + \\theta_3x^3 + \\theta_4x^4$.\n",
    "\n",
    "Bài toán này bị Overfitting (đường màu xanh dương) nên bạn muốn loại bỏ các giá trị $\\theta_3x^3 + \\theta_4x^4$ để tránh Overfitting (đường màu hồng). Khi đó chúng ta có thể thay đổi Cost Function như sau:\n",
    "\n",
    "> $\\frac{1}{2m} \\sum_{i = 1}^{m} (h_\\theta(x^{(i)} - y^{(i)}))^2 + 1000.\\theta_3^2 + 1000.\\theta_4^2$\n",
    "\n",
    "Bây giờ, khi thực hiện tối ưu hoá $\\theta$ để $J(\\theta)$ đạt giá trị nhỏ nhất thì $\\theta_3$ và $\\theta_4$ gần bằng 0 (và coi như có thể loại bỏ) - khi đó kết quả sẽ được như đường màu hồng. \n",
    "\n",
    "<img src=\"images/reg_1.png\" style=\"width:40%;height:40%;\">\n",
    "\n",
    "#### 2.2 L2 Regularization\n",
    "\n",
    "Nếu độ phức tạp của mô hình là một hàm của trọng số ($\\theta$ hay còn gọi là weight), thì trọng số càng lớn sẽ khiến mô hình trở lên phức tạp hơn so với các feature có trọng số nhỏ. \n",
    "\n",
    "Chúng ta có đánh giá độ phức tạp này bằng L2 Regularization là tổng bình phương của tất cả các trọng số ($\\theta$):\n",
    "\n",
    "> $ L_2 = ||\\theta||^2_2 = \\theta_1^2 + \\theta_2^2 + ... + \\theta_n^2$\n",
    "\n",
    "Trong công thức này, các trọng số gần bằng 0 sẽ ít ảnh hưởng đến độ phức tạp mô hình.\n",
    "\n",
    "\n",
    "**Tổng quát hoá bài toán:**\n",
    "\n",
    "Chúng ta có thể thêm vào hàm mất mát giá trị như sau:\n",
    "\n",
    "> $J(\\theta) = \\frac{1}{2m} [\\sum_{i = 1}^{m} (h_\\theta(x^{(i)}) - y^{(i)})^2 + \\lambda \\sum_{j = 1}^{n}\\theta_j^2]$\n",
    "\n",
    "**Lưu ý:** Không đánh phạt hệ số $\\theta_0$.\n",
    "\n",
    "Trong đó:\n",
    "- $\\lambda$ hay lambda là hệ số Regularization. Các bạn có thể thử thay đổi các giá trị tuỳ chỉnh tại https://www.desmos.com/calculator/1hexc8ntqp để hình dung dễ hơn.\n",
    "- Giá trị của $\\lambda$ thường nhỏ. Chúng ta sẽ học cách lựa chọn $\\lambda$ tối ưu trong phần bài tập.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Regularized Linear Regression\n",
    "\n",
    "##### Cost Function \n",
    "\n",
    "Hàm Cost sau khi thêm Regularization.\n",
    "\n",
    "> $J(\\theta) = \\frac{1}{2m} [\\sum_{i = 1}^{m} (h_\\theta(x^{(i)}) - y^{(i)})^2 + \\lambda \\sum_{j = 1}^{n}\\theta_j^2]$\n",
    "\n",
    "Lưu ý rằng không đánh phạt hệ số $\\theta_0$.\n",
    "\n",
    "##### Gradient Descent\n",
    "\n",
    "> Thực hiện đạo hàm $J$ lần lượt theo các tham số $\\theta_0, \\theta_1 ... \\theta_n$ .\n",
    "> Không đánh phạt $\\theta_0$.\n",
    "> Lặp lại cho đến khi hội tụ:\n",
    ">\n",
    "> {\n",
    ">\n",
    "> $\\theta_0 := \\theta_0 - \\alpha \\dfrac{1}{m} \\sum_{i=1}^m {(h_{\\theta}(x^{(i)}) - y^{(i)})}.x_0^{(i)} $\n",
    ">\n",
    "> $\\theta_j := \\theta_j - \\alpha \\dfrac{1}{m} [ \\sum_{i=1}^m {(h_{\\theta}(x^{(i)}) -y^{(i)})}.x_j^{(i)} + \\lambda\\theta_j ]\n",
    "; j \\in (1, 2, ..., n) $\n",
    ">\n",
    "> }\n",
    "\n",
    "**Vector hoá:**\n",
    "\n",
    "> $\\theta:= \\theta - \\frac{\\alpha}{m} [X^T (X\\theta - \\vec{y}) + \\lambda\\theta']$\n",
    "\n",
    "Trong đó:\n",
    "- $\\theta'$ có giá trị $\\theta_0 = 0$ (vì không đánh phạt $\\theta_0$), các giá trị còn lại tương tự với $\\theta$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Regularized Logistic Regression\n",
    "\n",
    "##### Cost Function \n",
    "\n",
    "Hàm Cost sau khi thêm Regularization.\n",
    "\n",
    "> $J(\\theta) = - \\frac{1}{m} [ \\sum_{i = 1}^{m}  y^{(i)}\\log{h(x^{(i)})} +  (1 - y^{(i)})\\log{(1 - h(x^{(i)}))} ] + \\frac{\\lambda}{2m} \\sum_{j = 1}^{n} \\theta_j^2$\n",
    "\n",
    "\n",
    "Lưu ý rằng không đánh phạt hệ số $\\theta_0$. Số 2 được thêm vào mẫu $\\frac{\\lambda}{2m}$ để khi thực hiện đạo hàm $J$ theo $\\theta$ sẽ triệt tiêu 2 dưới mẫu.\n",
    "\n",
    "- Vector hoá:\n",
    "\n",
    "> $J(\\theta) = - \\frac{1}{m} [ y^T \\log{h} + (1-y)^T\\log{(1 - h)} ] + \\frac{\\lambda}{2m} \\sum_{j = 1}^{n} \\theta_j^2$\n",
    "\n",
    "##### Gradient Descent (Giống với Linear Regression)\n",
    "\n",
    "> Thực hiện đạo hàm $J$ lần lượt theo các tham số $\\theta_0, \\theta_1 ... \\theta_n$ .\n",
    "> Không đánh phạt $\\theta_0$.\n",
    "> Lặp lại cho đến khi hội tụ:\n",
    ">\n",
    "> {\n",
    ">\n",
    "> $\\theta_0 := \\theta_0 - \\alpha \\dfrac{1}{m} \\sum_{i=1}^m {(h_{\\theta}(x^{(i)}) - y^{(i)})}.x_0^{(i)} $\n",
    ">\n",
    "> $\\theta_j := \\theta_j - \\alpha \\dfrac{1}{m} [ \\sum_{i=1}^m {(h_{\\theta}(x^{(i)}) -y^{(i)})}.x_j^{(i)} + \\lambda\\theta_j ]\n",
    "; j \\in (1, 2, ..., n) $\n",
    ">\n",
    "> }\n",
    "\n",
    "**Vector hoá:**\n",
    "\n",
    "> $\\theta:= \\theta - \\frac{\\alpha}{m} [X^T (g(X\\theta) - \\vec{y}) + \\lambda\\theta']$\n",
    "\n",
    "Trong đó:\n",
    "- $\\theta'$ có giá trị $\\theta_0 = 0$ (vì không đánh phạt $\\theta_0$), các giá trị còn lại tương tự với $\\theta$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tài liệu tham khảo \n",
    "\n",
    "[1] [Underfitting and Overfitting in Machine Learning](https://www.geeksforgeeks.org/underfitting-and-overfitting-in-machine-learning/)\n",
    "\n",
    "[2] [Overfitting - Blog: Machine Learning Cơ Bản](https://machinelearningcoban.com/2017/03/04/overfitting/)\n",
    "\n",
    "[3] [CS229 - Machine Learning](https://www.coursera.org/learn/machine-learning/resources/Zi29t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
